{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a09d4fb-60c5-4f45-b844-8c788a50c543",
    "_uuid": "8e892e637f005dd61ec7dcb95865e52f3de2a77f"
   },
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "\n",
    "Open in Colab  \n",
    "https://colab.research.google.com/github/sidkwon/kaggle-titanic/blob/master/titanic-solution.ipynb\n",
    "\n",
    "Based on https://github.com/minsuk-heo/kaggle-titanic\n",
    "\n",
    "\n",
    "### Predict survival on the Titanic\n",
    "- Defining the problem statement\n",
    "- Collecting the data\n",
    "- Exploratory data analysis\n",
    "- Feature engineering\n",
    "- Modelling\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap: ML process\n",
    "![ml_process](./images/ml_process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4af5e83d-7fd8-4a61-bf26-9583cb6d3476",
    "_uuid": "65d04d276a8983f62a49261f6e94a02b281dbcc9"
   },
   "source": [
    "## 1. Defining the problem statement\n",
    "Complete the analysis of what sorts of people were likely to survive.  \n",
    "In particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f529075-7f9b-40ff-a79a-f3a11a7d8cbe",
    "_uuid": "64ca0f815766e3e8074b0e04f53947930cb061aa"
   },
   "source": [
    "## 2. Collecting the data\n",
    "\n",
    "training data set and testing data set are given by Kaggle\n",
    "you can download from  \n",
    "my github [https://github.com/minsuk-heo/kaggle-titanic/tree/master](https://github.com/minsuk-heo/kaggle-titanic)  \n",
    "or you can download from kaggle directly [kaggle](https://www.kaggle.com/c/titanic/data)  \n",
    "\n",
    "### load train, test dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e58a3f06-4c2a-4b87-90de-f8b09039fd4e",
    "_uuid": "46f0b12d7bf66712642e9a9b807f5ef398426b83"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/sidkwon/kaggle-titanic/master/input/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/sidkwon/kaggle-titanic/master/input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "836a454f-17bc-41a2-be69-cd86c6f3b584",
    "_uuid": "1ed3ad39ead93977b8936d9c96e6f6f806a8f9b3"
   },
   "source": [
    "## 3. Exploratory data analysis\n",
    "Printing first 5 rows of the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "749a3d70-394c-4d2c-999a-4d0567e39232",
    "_uuid": "b9fdb3b19d7a8f30cd0bb69ae434e04121ecba93"
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "- Survived: \t0 = No, 1 = Yes  \n",
    "- pclass: \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd  \t\n",
    "- sibsp:\t# of siblings / spouses aboard the Titanic  \t\n",
    "- parch:\t# of parents / children aboard the Titanic  \t\n",
    "- ticket:\tTicket number\t\n",
    "- cabin:\tCabin number\t\n",
    "- embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ebc1e0e-2b5a-4d92-98e0-defa019d4439",
    "_uuid": "1892fbb34b26d775d1c428fdb7b6254449286b28"
   },
   "source": [
    "**Total rows and columns**\n",
    "\n",
    "We can see that there are 891 rows and 12 columns in our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed1e7849-d1b6-490d-b86b-9ca71dfafc7d",
    "_uuid": "5a641beccf0e555dfd7b9a53a17188ea6edef95b"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "418b8a69-f2aa-442d-8f45-fa8887190938",
    "_uuid": "4ee2591110660a4a16b3da7a7530f0945e121b46"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abc3c4fc-6419-405f-927a-4214d2c73eec",
    "_uuid": "622d4d4b2ba8f77cc537af97fc343d4cd6de26b2"
   },
   "source": [
    "We can see that **Age** value is missing for many rows. \n",
    "\n",
    "Out of 891 rows, the **Age** value is present only in 714 rows.\n",
    "\n",
    "Similarly, **Cabin** values are also missing in many rows. Only 204 out of 891 rows have *Cabin* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0663e2bb-dc27-4187-94b1-ff4ff78b68bc",
    "_uuid": "3bf74de7f2483d622e41608f6017f2945639e4df"
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "176aa52d-fde8-42e6-a3ee-db31f8b0ca49",
    "_uuid": "b48a9feff6004d783960aa1b32fdfde902d87e21"
   },
   "source": [
    "There are 177 rows with missing *Age*, 687 rows with missing *Cabin* and 2 rows with missing *Embarked* information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c8553d48-c5e0-4947-bd13-1b38509c850c",
    "_uuid": "1a28e607e9ed63cefe0f35a4e4d72f2f36299323"
   },
   "source": [
    "### import python lib for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1d8a6d2-c22d-435c-8c98-973e8f41b138",
    "_uuid": "26411c710f69b29939c815d5f5ab01d9177df7d0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set() # setting seaborn default for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart for Categorical Features\n",
    "- Pclass\n",
    "- Sex\n",
    "- SibSp ( # of siblings and spouse)\n",
    "- Parch ( # of parents and children)\n",
    "- Embarked\n",
    "- Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(feature):\n",
    "    survived = train[train['Survived']==1][feature].value_counts()\n",
    "    dead = train[train['Survived']==0][feature].value_counts()\n",
    "    df = pd.DataFrame([survived,dead])\n",
    "    df.index = ['Survived','Dead']\n",
    "    df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **Women** more likely survivied than **Men**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **1st class** more likely survivied than **other classes**  \n",
    "The Chart confirms **3rd class** more likely dead than **other classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('SibSp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded with more than 2 siblings or spouse** more likely survived  \n",
    "The Chart confirms **a person aboarded without siblings or spouse** more likely dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Parch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded with more than 2 parents or children** more likely survived  \n",
    "The Chart confirms **a person aboarded alone** more likely dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded from C** slightly more likely survived  \n",
    "The Chart confirms **a person aboarded from Q** more likely dead  \n",
    "The Chart confirms **a person aboarded from S** more likely dead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "810cd964-24eb-44fb-9e7b-18bbddd4900f",
    "_uuid": "fd86ccdf2d1248b79c68365444e96e46a50f3f5a"
   },
   "source": [
    "## 4. Feature engineering\n",
    "\n",
    "Feature engineering is the process of using domain knowledge of the data  \n",
    "to create features (**feature vectors**) that make machine learning algorithms work.  \n",
    "\n",
    "feature vector is an n-dimensional vector of numerical features that represent some object.  \n",
    "Many algorithms in machine learning require a numerical representation of objects,  \n",
    "since such representations facilitate processing and statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 how titanic sank?\n",
    "sank from the bow of the ship where third class rooms located  \n",
    "conclusion, **Pclass** is key feature for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/t/5090b249e4b047ba54dfd258/1351660113175/TItanic-Survival-Infographic.jpg?format=1500w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Name' 컬럼에서 영어 호칭을 추출하기 위해 pandas의 str.extract() 메소드를 사용한다.  \n",
    "- str.extract(): https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html  \n",
    "- RegExr: https://regexr.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [train, test] # combining train and test dataset\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False) # expand=True; return dataframe, expand=False; return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title map\n",
    "Mr : 0  \n",
    "Miss : 1  \n",
    "Mrs: 2  \n",
    "Others: 3  \n",
    "\n",
    "pandas.Series.map: https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n",
    "                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n",
    "                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary feature from dataset\n",
    "# pandas.DataFrame.drop: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop\n",
    "train.drop('Name', axis=1, inplace=True)\n",
    "test.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sex\n",
    "\n",
    "male: 0\n",
    "female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {\"male\": 0, \"female\": 1}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 some age is missing\n",
    "Let's use Title's median age for missing Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\n",
    "train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "test[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas.DataFrame.groupby\n",
    "![](./images/pandas_groupby.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = train.groupby(\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform: 데이터프레임에 그룹 단위로 통계량을 집계해서 칼럼 추가  \n",
    "df.groupby(['group']).col.transform('count')\n",
    "\n",
    "![](./images/pandas_groupby_transform.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(30)\n",
    "train.groupby(\"Title\")[\"Age\"].transform(\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**seaborn.FacetGrid**  \n",
    "Multi-plot grid for plotting conditional relationships.  \n",
    "https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\n",
    "\n",
    "**seaborn.kdeplot**\n",
    "Plot univariate or bivariate distributions using kernel density estimation.  \n",
    "https://seaborn.pydata.org/generated/seaborn.kdeplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hue: train dataframe을 \"Survived\" 컬럼 기준으로 나눈다\n",
    "# height: 각 facet의 height(in inches)\n",
    "# aspect: 각 facet의 화면비율, aspect=4는 4:1을 의미\n",
    "facet = sns.FacetGrid(train, hue=\"Survived\", height=4, aspect=4)\n",
    "\n",
    "# facet.map: Facet grid에 kdeplot을 그린다 (Parameter: 사용할 그래프 이름, 시각화를 진행할 dataframe의 컬럼명, 채우기(fill)여부 )\n",
    "facet.map(sns.kdeplot,'Age',shade=True)\n",
    "\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(30, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Binning\n",
    "Binning/Converting Numerical Age to Categorical Variable  \n",
    "\n",
    "feature vector map:  \n",
    "child: 0  \n",
    "young: 1  \n",
    "adult: 2  \n",
    "mid-age: 3  \n",
    "senior: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pandas_selection](./images/pandas_selection.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class','2nd class', '3rd class']\n",
    "df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more than 50% of 1st class are from S embark  \n",
    "more than 50% of 2nd class are from S embark  \n",
    "more than 50% of 3rd class are from S embark\n",
    "\n",
    "**fill out missing embark with S embark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing Fare with median fare for each Pclass\n",
    "train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\n",
    "\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class','2nd class', '3rd class']\n",
    "\n",
    "df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling을 위해 작은 숫자를 사용\n",
    "cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing Fare with median fare for each Pclass\n",
    "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "test[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'FamilySize',shade= True)\n",
    "facet.set(xlim=(0, train['FamilySize'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "for dataset in train_test_data:\n",
    "    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['Ticket', 'SibSp', 'Parch']\n",
    "train = train.drop(features_drop, axis=1)\n",
    "test = test.drop(features_drop, axis=1)\n",
    "train = train.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.drop('Survived', axis=1)\n",
    "target = train['Survived']\n",
    "\n",
    "train_data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 Dataframe 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"train_data.pkl\")\n",
    "target.to_pickle(\"target.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Added\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Cross Validation (K-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Ramdom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(score)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.6 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(score)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.7 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(score)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.8 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(tree_method='hist', n_estimators=10)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(score)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': randint(5, 20),\n",
    "    'max_depth': randint(6, 15),\n",
    "    'min_sample_split': randint(2, 25),\n",
    "    'min_sample_leaf': randint(1, 25),\n",
    "    'learning_rate': uniform(0.0001, 0.002)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = RandomizedSearchCV(XGBClassifier(tree_method='hist', n_estimators=10), params, n_iter=100, n_jobs=-1)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(gs, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(score)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(train_data, target)\n",
    "\n",
    "test_data = test.drop(\"PassengerId\", axis=1).copy()\n",
    "prediction = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": prediction\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "This notebook is created by learning from the following notebooks:\n",
    "\n",
    "- [Mukesh ChapagainTitanic Solution: A Beginner's Guide](https://www.kaggle.com/chapagain/titanic-solution-a-beginner-s-guide?scriptVersionId=1473689)\n",
    "- [How to score 0.8134 in Titanic Kaggle Challenge](http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)\n",
    "- [Titanic: factors to survive](https://olegleyz.github.io/titanic_factors.html)\n",
    "- [Titanic Survivors Dataset and Data Wrangling](http://www.codeastar.com/data-wrangling/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
